{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning with TensorFlow\n",
        "\n",
        "* In the previous unit, we have seen how to build a DNN classifier\n",
        "  \"from scratch\".\n",
        "\n",
        "* Knowing how to do this is knowledge at the level of\n",
        "  \"knowing how to derive the Euler-Lagrange equations\":\n",
        "  \n",
        "  We may well find ourselves in some unusual situation\n",
        "  where we have to \"go back to first principles\" to reason something out.\n",
        "\n",
        "* Much of current ML work (model-defining, model-training) is framework-based,\n",
        "  but there is both a blessing and a curse here:\n",
        "  * Frameworks cover many common cases.\n",
        "  * They also may limit our perspective to the framework's narrow field-of-view.\n",
        "  * Interesting work remains to be done that will require extending frameworks,\n",
        "    or even \"working outside existing frameworks since we have to break some\n",
        "    rules\".\n",
        "\n",
        "* Here, we will mostly focus on Google's TensorFlow library.\n",
        "  Later, we will also look a bit into JAX.\n",
        "\n",
        "  * TensorFlow is a well-supported evolving (but somewhat under-documented)\n",
        "    library that is popular for ML, and has been designed for ML,\n",
        "    but can be used for many other tasks as well. \"A frigate\".\n",
        "  * JAX is a smaller and more experimental project that \"tries to\n",
        "    take the good bits and pieces from TensorFlow\", such as\n",
        "    \"fast gradients\" and \"accelerated linear algebra\". \"A skiff\"."
      ],
      "metadata": {
        "id": "sLLTJL5z-kj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow for the ML Practitioner\n",
        "\n",
        "Suppose we wanted to redo what we did by hand using the infrastructure provided by TensorFlow. Here is an \"easy sailing\" version.\n",
        "\n",
        "First, let us train a model (we will come back to discussing all the nice things that we are getting for free here thanks to TensorFlow)."
      ],
      "metadata": {
        "id": "ZaOLb1-NhbPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need this PyPI module later\n",
        "!pip install tf2onnx\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "# Loading the training and test set. We split the training-set into 'training',\n",
        "# 'validation', and 'extra' for ad-hoc purposes.\n",
        "def get_training_datasets():\n",
        "  (ds_train_raw,\n",
        "   ds_validation_raw,\n",
        "   ds_extra_raw,\n",
        "   ds_test_raw), ds_info = tfds.load(\n",
        "      'mnist',\n",
        "      split=['train[:75%]', 'train[75%:99%]', 'train[99%:]', 'test'],\n",
        "      shuffle_files=True,\n",
        "      as_supervised=True,\n",
        "      with_info=True)\n",
        "  total_num_examples = sum(s.num_examples for s in ds_info.splits.values())\n",
        "  #\n",
        "  def normalize_image(image, label):\n",
        "    \"\"\"Normalizes images.\"\"\"\n",
        "    return tf.cast(image, tf.float32) / 255., label\n",
        "  #\n",
        "  def transform(ds):\n",
        "    return (ds\n",
        "            .map(normalize_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .cache()\n",
        "            # Shuffle buffer size needs to be at least as large as the number\n",
        "            # of examples - but does not matter much otherwise.\n",
        "            .shuffle(total_num_examples, seed=0)\n",
        "            .batch(32)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "  #\n",
        "  return (transform(ds_train_raw),\n",
        "          transform(ds_validation_raw),\n",
        "          transform(ds_extra_raw),\n",
        "          transform(ds_test_raw))\n",
        "\n",
        "\n",
        "ds_train, ds_validation, ds_extra, ds_test = get_training_datasets()"
      ],
      "metadata": {
        "id": "nPMo0X_vnGdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and test sets are iterators.\n",
        "# For later, we save part of the `ds_extra` dataset to the filesystem.\n",
        "\n",
        "# The os.access() check makes this cell idempotent.\n",
        "if os.access('training_examples.npz', os.R_OK):\n",
        "  print('Small sample dataset already was saved to filesystem.')\n",
        "else:\n",
        "  sample_batches = list(ds_extra.take(10).as_numpy_iterator())\n",
        "  sample_batches_images = numpy.stack(\n",
        "    [image_data for image_data, labels in sample_batches], axis=0)\n",
        "  sample_batches_labels = numpy.stack(\n",
        "    [labels for image_data, labels in sample_batches], axis=0)\n",
        "  #\n",
        "  # `sample_batches_images` is a `[num_batches, 32, 28, 28, 1]`-array:\n",
        "  # `num_batches` batches of 32 images each which are 28x28 with one\n",
        "  #  color-channel.\n",
        "  # `training_batches_labels` is a `[num_batches, 32]`-array:\n",
        "  #  One label per batch per image in the batch.\n",
        "  print('Shapes:', sample_batches_images.shape, sample_batches_labels.shape)\n",
        "  print('Labels:\\n', sample_batches_labels, sep='')\n",
        "  #\n",
        "  numpy.savez_compressed('training_examples.npz',\n",
        "                         images=sample_batches_images,\n",
        "                         labels=sample_batches_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w73Hpk4Hx0Ie",
        "outputId": "c272989a-236f-42a1-db1d-1ee4f2dd1268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (10, 32, 28, 28, 1) (10, 32)\n",
            "Labels:\n",
            "[[6 2 3 1 6 9 3 6 1 2 5 4 2 1 5 8 5 7 6 9 3 8 6 4 1 5 9 8 3 2 6 9]\n",
            " [7 2 9 9 9 5 4 4 0 8 2 8 7 4 1 2 6 8 3 4 5 8 0 5 2 8 9 7 5 8 5 7]\n",
            " [3 9 6 9 1 3 2 3 0 7 7 2 4 6 1 7 4 3 3 9 4 1 1 2 1 4 6 2 2 8 6 4]\n",
            " [2 8 4 3 3 5 6 4 1 1 1 5 7 7 5 7 4 5 1 5 7 3 0 1 1 2 8 8 5 1 7 1]\n",
            " [0 1 3 3 5 6 0 3 9 1 7 0 7 3 1 9 4 5 5 8 8 6 1 7 3 7 2 6 7 1 7 3]\n",
            " [7 9 0 8 8 7 4 3 6 5 8 8 9 8 1 7 3 4 1 9 5 7 8 1 9 4 0 7 2 3 4 5]\n",
            " [2 0 7 2 8 6 2 3 6 1 9 2 7 4 4 8 4 1 5 2 7 2 0 8 8 3 9 3 3 0 3 4]\n",
            " [2 3 8 5 0 1 6 5 5 0 8 5 9 9 4 8 8 1 4 4 9 8 4 4 6 5 3 0 8 8 1 7]\n",
            " [6 0 1 6 8 2 3 9 4 8 1 1 0 4 4 2 3 4 1 0 5 1 9 0 0 6 2 7 5 2 7 9]\n",
            " [1 8 4 9 2 1 9 1 0 8 0 1 4 4 7 5 3 8 2 9 9 4 1 6 2 5 8 1 1 3 7 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Training a model.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(50, activation='tanh'),\n",
        "  tf.keras.layers.Dense(50, activation='tanh'),\n",
        "  tf.keras.layers.Dense(50, activation='tanh'),\n",
        "  tf.keras.layers.Dense(50, activation='tanh'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Participant Exercise: Try out other architectures, such as...:\n",
        "#\n",
        "# model = tf.keras.models.Sequential([\n",
        "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "#   tf.keras.layers.Dense(80, activation='relu'),\n",
        "#   tf.keras.layers.Dense(80, activation='relu'),\n",
        "#   tf.keras.layers.Dense(80, activation='relu'),\n",
        "#   tf.keras.layers.Dense(10)\n",
        "# ])\n",
        "#\n",
        "# How simple can we make this and still get >95% accuracy?\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    validation_data=ds_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8abSmYz9nE",
        "outputId": "4b8eede5-84a0-40ab-ef3a-ee9c86141b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 33s 10ms/step - loss: 0.7655 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.4042 - val_sparse_categorical_accuracy: 0.8922\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.3063 - val_sparse_categorical_accuracy: 0.9135\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.2651 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9244\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9310\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1996 - sparse_categorical_accuracy: 0.9425 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9373\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1778 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.1988 - val_sparse_categorical_accuracy: 0.9422\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9541 - val_loss: 0.1862 - val_sparse_categorical_accuracy: 0.9474\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1447 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9469\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9513\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dd008367700>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a trained model. Perhaps not one with quite state-of-the-art\n",
        "performance, but at least a model that clearly seems to know something about the task it was being built for.\n",
        "\n",
        "Let us see how to:\n",
        "  * Get information about the trained model.\n",
        "  * Save it to a file and load it again.\n",
        "  * Actually use it to make predictions."
      ],
      "metadata": {
        "id": "XqWNzDFN3PhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "# Saving to a `*.h5` file will make tf-Keras use the HDF5 format\n",
        "# for the saved model.\n",
        "model.save(\"mnist_model.h5\")\n",
        "\n",
        "print('######')\n",
        "!ls -lah mnist_model*\n",
        "\n",
        "reloaded_model = tf.keras.models.load_model(\"mnist_model.h5\")\n",
        "\n",
        "\n",
        "# Let us use one batch of examples we extracted earlier:\n",
        "examples_images, examples_labels = (\n",
        "    sample_batches_images[0, ...], sample_batches_labels[0, ...])\n",
        "\n",
        "def predict(image, verbose=False):\n",
        "  if image.size != 28*28:\n",
        "    raise ValueError('Expecting input data to provide 28x28 pixels.')\n",
        "  logits = model.predict(image.reshape(1, 28, 28), verbose=verbose)\n",
        "  if verbose:\n",
        "    print('Logits:', logits.round(3))\n",
        "  return numpy.argmax(logits)\n",
        "\n",
        "# We could run predictions on an entire batch, but here process\n",
        "# individual images.\n",
        "for num_example, (image, label) in enumerate(zip(examples_images,\n",
        "                                                 examples_labels)):\n",
        "  predicted = predict(image, verbose=False)  # Feel free to set verbose=True\n",
        "  ok = 'OK' if predicted == label else 'BAD'\n",
        "  print(f'Example Image {num_example:2d}: '\n",
        "        f'predicted={predicted}, actual={label}  - {ok}')\n"
      ],
      "metadata": {
        "id": "r3mtpLROpqUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3e63bc-0610-4bf5-f9bb-8ceb883da5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                39250     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47,410\n",
            "Trainable params: 47,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "######\n",
            "-rw-r--r-- 1 root root 605K Aug 22 11:34 mnist_model.h5\n",
            "Example Image  0: predicted=6, actual=6  - OK\n",
            "Example Image  1: predicted=2, actual=2  - OK\n",
            "Example Image  2: predicted=3, actual=3  - OK\n",
            "Example Image  3: predicted=1, actual=1  - OK\n",
            "Example Image  4: predicted=6, actual=6  - OK\n",
            "Example Image  5: predicted=9, actual=9  - OK\n",
            "Example Image  6: predicted=3, actual=3  - OK\n",
            "Example Image  7: predicted=6, actual=6  - OK\n",
            "Example Image  8: predicted=1, actual=1  - OK\n",
            "Example Image  9: predicted=7, actual=2  - BAD\n",
            "Example Image 10: predicted=5, actual=5  - OK\n",
            "Example Image 11: predicted=4, actual=4  - OK\n",
            "Example Image 12: predicted=2, actual=2  - OK\n",
            "Example Image 13: predicted=1, actual=1  - OK\n",
            "Example Image 14: predicted=5, actual=5  - OK\n",
            "Example Image 15: predicted=8, actual=8  - OK\n",
            "Example Image 16: predicted=5, actual=5  - OK\n",
            "Example Image 17: predicted=7, actual=7  - OK\n",
            "Example Image 18: predicted=6, actual=6  - OK\n",
            "Example Image 19: predicted=7, actual=9  - BAD\n",
            "Example Image 20: predicted=3, actual=3  - OK\n",
            "Example Image 21: predicted=8, actual=8  - OK\n",
            "Example Image 22: predicted=6, actual=6  - OK\n",
            "Example Image 23: predicted=4, actual=4  - OK\n",
            "Example Image 24: predicted=1, actual=1  - OK\n",
            "Example Image 25: predicted=5, actual=5  - OK\n",
            "Example Image 26: predicted=9, actual=9  - OK\n",
            "Example Image 27: predicted=8, actual=8  - OK\n",
            "Example Image 28: predicted=3, actual=3  - OK\n",
            "Example Image 29: predicted=2, actual=2  - OK\n",
            "Example Image 30: predicted=6, actual=6  - OK\n",
            "Example Image 31: predicted=9, actual=9  - OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While we are at it: A 'trained ML model' is a bit like an 'electronics module': We would typically like to know how to use this as a component in some larger engineering design (/ product).\n",
        "\n",
        "It is quite possible to use trained TensorFlow models on smartphones, advanced microcontrollers, or merely make them part of some compiled application. Often, a good approach is to convert the model to \"TensorFlow Lite\" form for deployment.\n",
        "\n",
        "There are TFLite libraries for various systems/architectures to then load a model, feed input to it, and obtain predictions from it. These exist for: microcontrollers, tiny computers such as the Raspberry Pi, Android apps, iOS apps, compiled binaries, etc.\n",
        "\n",
        "Here, we will just sketch how this looks like using again Python-TFLite - so, we are not quite cutting the Python umbilical cord yet. We will first save our model in TFLite form, and then switch over from using TensorFlow to using only the TFLite module."
      ],
      "metadata": {
        "id": "HQB-Oy7z37xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the model to TFLite (\"TensorFlow Lite\") form.\n",
        "\n",
        "model = tf.keras.models.load_model(\"mnist_model.h5\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('mnist_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!ls -lah 'mnist_model.tflite'"
      ],
      "metadata": {
        "id": "v1vkqQ8FvC36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cf0eb1-4321-4bc0-a7f1-b512b25da104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 189K Aug 22 11:34 mnist_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For later, we can also convert the trained model to `.onnx` format, which is understood by other projects as a representation of a computational graph. For graphs that do not use too exotic computational operations, this should generally work. At the time of this writing, we cannot convert from a model saved in HDF5 format, so we need to save our model again in TensorFlow's own format. Rather than importing the `tf2onnx` module here, we perform conversion in a subprocess, executed via a shell escape."
      ],
      "metadata": {
        "id": "zc1fma2HCmhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mnist_model_tf\")\n",
        "\n",
        "!python -m tf2onnx.convert --saved-model mnist_model_tf --output mnist_model.onnx\n",
        "!ls -lah mnist_model.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJKGeRCpARSv",
        "outputId": "90f7fec0-fe49-46cc-96e7-e0a7c70f5d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-08-22 11:42:04,202 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-08-22 11:42:04,486 - INFO - Signatures found in model: [serving_default].\n",
            "2023-08-22 11:42:04,486 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-08-22 11:42:04,486 - INFO - Output names: ['dense_4']\n",
            "2023-08-22 11:42:04,566 - INFO - Using tensorflow=2.12.0, onnx=1.14.0, tf2onnx=1.15.0/6d6b6c\n",
            "2023-08-22 11:42:04,566 - INFO - Using opset <onnx, 15>\n",
            "2023-08-22 11:42:04,572 - INFO - Computed 0 values for constant folding\n",
            "2023-08-22 11:42:04,586 - INFO - Optimizing ONNX model\n",
            "2023-08-22 11:42:04,629 - INFO - After optimization: Cast -1 (1->0), Identity -2 (2->0)\n",
            "2023-08-22 11:42:04,631 - INFO - \n",
            "2023-08-22 11:42:04,631 - INFO - Successfully converted TensorFlow model mnist_model_tf to ONNX\n",
            "2023-08-22 11:42:04,631 - INFO - Model inputs: ['flatten_input']\n",
            "2023-08-22 11:42:04,631 - INFO - Model outputs: ['dense_4']\n",
            "2023-08-22 11:42:04,631 - INFO - ONNX model is saved at mnist_model.onnx\n",
            "-rw-r--r-- 1 root root 605K Aug 22 11:34 mnist_model.h5\n",
            "-rw-r--r-- 1 root root 190K Aug 22 11:42 mnist_model.onnx\n",
            "-rw-r--r-- 1 root root 189K Aug 22 11:34 mnist_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us actually download the `.tflite` and also `.onnx` file locally..."
      ],
      "metadata": {
        "id": "A5bXi23mTtPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.files\n",
        "google.colab.files.download('mnist_model.tflite')\n",
        "google.colab.files.download('mnist_model.onnx')"
      ],
      "metadata": {
        "id": "GjzI8lZqT7-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: For some versions of TensorFlow and TFLite, it is not possible\n",
        "# to import `tflite` and `tensorflow` into the same Python process.\n",
        "#\n",
        "# This normally is not even needed, given that `tf` has a `tf.lite` sub-module,\n",
        "# but here we want to demonstrate using TFlite only and not the full-blown\n",
        "# TensorFlow module.\n",
        "#\n",
        "# If executing this cell fails, then restarting the Colab runtime will\n",
        "# replace the running Python interpreter with a new one while retaining\n",
        "# on-filesystem state of the virtual machine. So, it might be necessary to\n",
        "# do [Runtime] -> [Restart Runtime] (Short-cut: Control-M dot) before\n",
        "# continuing with this notebook by executing this cell.\n",
        "#\n",
        "# Since the runtime system may have been restarted here,\n",
        "# we re-import the modules that we will need going forward.\n",
        "\n",
        "# Note: On non-colab systems, if `tflite-runtime` is not yet available\n",
        "# for too-recent a CPython version, this might require e.g.\n",
        "# python3.10 -m pip install tflite-runtime\n",
        "!pip install tflite-runtime\n",
        "\n",
        "import time\n",
        "import numpy\n",
        "import tflite_runtime.interpreter as tflite\n",
        "\n",
        "reloaded_examples = numpy.load('training_examples.npz')\n",
        "sample_batches_images =  reloaded_examples['images']\n",
        "sample_batches_labels =  reloaded_examples['labels']"
      ],
      "metadata": {
        "id": "g0dNEd45t3c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9486da-f947-42ea-a34f-7ac5d99af6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflite-runtime in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from tflite-runtime) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_tflite_predictor(model_path):\n",
        "  interpreter = tflite.Interpreter(model_path=model_path)\n",
        "  interpreter.allocate_tensors()\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  def fn_predict(in_data, verbose=False):\n",
        "    t0 = time.time()\n",
        "    # Note that this is not reentrant! Different invocations of the current\n",
        "    # function use the same `interpreter`, and mutate its state by\n",
        "    # \"setting the input\". So, if multithreading executed called a function\n",
        "    # that does this concurrently more-than-once-at-the-same-time, things\n",
        "    # would go wrong.\n",
        "    interpreter.set_tensor(input_details[0]['index'],\n",
        "                           in_data.reshape(1, 28, 28))\n",
        "    interpreter.invoke()\n",
        "    t1 = time.time()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    result = numpy.squeeze(output_data)\n",
        "    if verbose:\n",
        "      print(f'(t={(t1-t0)*1000:.3f} msec):', result.round(3))\n",
        "    return result\n",
        "  return fn_predict\n",
        "\n",
        "mnist_tflite_predictor = get_mnist_tflite_predictor(\n",
        "    model_path='mnist_model.tflite')\n",
        "\n",
        "print('Predicted: ',\n",
        "      numpy.argmax(mnist_tflite_predictor(sample_batches_images[0, 0, ...],\n",
        "                                          verbose=True)),\n",
        "      ' -  Actual: ', sample_batches_labels[0, 0])"
      ],
      "metadata": {
        "id": "wFxwPN4TxNsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92084eb-c47a-44dc-968e-1f289e933287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(t=0.906 msec): [-4.890e-01 -1.157e+00 -2.000e-03 -3.020e+00  8.140e-01  9.350e-01\n",
            "  8.952e+00 -8.248e+00 -7.890e-01 -3.224e+00]\n",
            "Predicted:  6  -  Actual:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What TensorFlow did for us here\n",
        "\n",
        "  * For simple multi-layer architectures:\n",
        "    * Provide us with an extremely simple way to specify a neural network.\n",
        "    * Automatically pick reasonable defaults for the distribution of\n",
        "      randomized initial weights and biases.\n",
        "    * Hide all the subtleties around computing fast gradients.\n",
        "  * Offer a convenient way to specify how we want to utilize gradients\n",
        "    for optimization.\n",
        "    \n",
        "    Earlier: 'multiply gradient with a small factor and\n",
        "    take a small step in the opposite direction (going down)'.\n",
        "    \n",
        "    Here: pick a very simple yet quite effective alternative strategy\n",
        "    known as 'Adam Optimization'.\n",
        "\n",
        "  * Allow us a convenient way to specify a loss function - here directly\n",
        "    from logits.\n",
        "    \n",
        "    (Earlier, we had to go from logits to probabilities,\n",
        "    do softmax, and then hand-backpropagate it all).\n",
        "\n",
        "  * Provide convenience functions for loading and transforming input data,\n",
        "    which include very substantial performance optimizations.\n",
        "  * Handle setting up the computation in such a way that training can optionally\n",
        "    run on CPU, GPU, or TPU(!)\n",
        "  * Provide us with a straightforward way to save and deploy a trained model.\n",
        "  * Allow us to specify performance metrics to track during training.\n",
        "\n",
        "### What we have not seen yet\n",
        "\n",
        "  * \"The scaffolding between this high-level perspective and the\n",
        "    low-level approach we discussed earlier.\"\n",
        "  * How to put unusual data-processing into TensorFlow so that we\n",
        "    can still use high level infrastructure like model-saving.\n",
        "  * How to use the \"tensor arithmetics with fast gradients\" machinery\n",
        "    inside TensorFlow to do non-ML physics.\n",
        "  * More tuning and tweaks we can apply to improve performance\n",
        "    (L2 regularization, architectural elements such as:\n",
        "    dropout layers, convolutional+max-pooling layers).\n",
        "\n",
        "### Additional remarks\n",
        "\n",
        " * On 'weight initialization': TensorFlow by default uses \"[Glorot](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) (or 'Xavier') initialization\" - basic idea: if N normal distributed inputs get summed over, use a 1/sqrt(N) scaling factor for random weight initialization.\n",
        " * Here, we are using the 'test set' to obtain performance metrics.\n",
        "   This is generally a bad idea, since it leads to applying tweaks based\n",
        "   on information obtained by \"peeking at test set performance\".\n",
        "\n",
        "   **If we want to report proper ability-to-generalize, we must not use\n",
        "   observations on the test set to make model tuning decisions.**\n",
        "\n",
        "   (The right thing to do here is to lock away the \"test set\" and split\n",
        "    the for-training examples into an actual 'training set for computing\n",
        "    gradients' and a 'validation set' for making tuning decisions.)\n",
        "\n",
        "   Overall, this example is mostly about showing \"how we can wire things up\",\n",
        "   and in this context, this is tolerable, since we are not out to\n",
        "   \"break the world record on MNIST classification\".\n",
        "\n",
        " * Nowadays, a ML system doing MNIST-classification is a bit like a TV\n",
        "   screen showing a test image - it merely indicates that we built\n",
        "   something which allows data to flow the way it should, and we might\n",
        "   be able to identify some glaring problems.\n"
      ],
      "metadata": {
        "id": "VbxH9qrS8ADN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture Improvements\n",
        "\n",
        "Before we \"open the engine hood\" and take a deeper look at the technology, let us discuss a few easy-to-explain ideas around \"what can we do here to further improve image classifier performance?\"\n",
        "\n",
        "There are some simple general ideas that are reasonably easy-to-explain in just one or two paragraphs - if we accept that the \"cheap heuristic explanations\" we are giving might actually be a little bit off. At this level, this is more \"cooking advice\" than a thorough discussion of deeper characteristics.\n",
        "\n",
        "##### **L2 Regularization**\n",
        "\n",
        "Now that we have seen how to train deep architectures: What would we expect to happen if we substantially over-sized or under-sized a model (in terms of number of layers and also units per layer) relative to what experimentation tells us is the point where increasing model size brings no further benefit?\n",
        "\n",
        "Under-sizing is easy to understand: The model will not be able to extract and process all the features that are in principle available, and will have to make hard choices what to ignore.\n",
        "\n",
        "Over-sizing is more interesting: If we massively over-sized the model, and used a fixed-size training set, it would at some point have enough capacity to just memorize every training example - and it may memorize such examples in weird ways, such as \"If the top right pixel is green and the top left pixel is brighter than its neighbors, then we know we are looking at example #1735\". Naturally, this then messes up the model's ability to generalize.\n",
        "*In particular*, if there is any classification error in the training set labels, the model will not do what an under-sized model would do - \"if I cannot do well and have to take a hit, I perhaps should take one on this crazy outlier in the data\". Rather, it would try to come up with a very fancy \"explanation\" why the outlier (and some region around it) is \"really special\".\n",
        "\n",
        "If we built a model with only linear activation functions, there would be no point going to two or more layers - since \"all transformations are linear\".\n",
        "So, the power of deep architectures is closely related to their ability to put nonlinearities to good use. If we used an architecture with tanh-activation as the nonlinearity on hidden layers, and a final linear scaling layer, then tanh-s that receive small-magnitude input would behave mostly-linear.\n",
        "\n",
        "With this in mind, it appears natural to try an approach where \"we give the network the ability to use many nonlinearities, but we attach a small price to it, so the network will only decide to actually use that power if that brings a benefit\".\n",
        "\n",
        "Now, we are in an \"optimize performance, but also do X\" (i.e. try not to use large weights) situation. We still want to consider ML training as a numerical optimization problem - but that then means that we have to slightly deviate from the idea of \"what we optimize for is performance\" towards \"our loss function is a weighted sum of contributions, where one measures performance, and the others are about other relevant aspects, such as minimizing some quantity that we believe to be a useful proxy for the model inclination to avoid unnecessarily complex explanations\".\n",
        "\n",
        "The basic idea behind \"L2 regularization\" is: Let us add a term to the total loss that is the sum-squared of weights. The model can use nonlinearity, and \"smallish weights are still cheap\", but making a weight large is considered costly.\n",
        "\n",
        "The effect is nicely illustrated in these two TensorFlow Playground training runs: Two large-capacity models trained on the same \"simple explanation but noisy data\" dataset, having the same outliers. Without L2 regularization, we see a tendency to \"draw a complicated border to explain the training set\". With L2 regularization, we get a nicer border. As expected, the complex border is related to \"overfitting\", and we do see an accuracy gap between training and test set.\n",
        "\n",
        "(See screenshots \"L2 Regularization\" on \"supplementary material\" document.)\n",
        "\n",
        "#### **ReLU activation**\n",
        "\n",
        "Traditionally, the earliest nonlinearity to be used widely in neural network research was the 'sigmoid' $x\\mapsto 1/(1+\\exp(-x))$ (this again is of course just the logistic function). The thinking here was that this should serve as a crude model for biological neurons that still allows us to do backpropagation: Zero output for low activation, saturation for high activation, but we want a continuous function.\n",
        "\n",
        "It so turns out that one can in principle use just about every \"not too wild\" nonlinearity for Deep Neural networks, even functions such as $x\\mapsto x^2$ or $x\\mapsto\\exp(-x^2/2)$. Overall, this might not be too surprising at least for smooth such functions - \"if we zoom in at some point, we will see linear behavior, if we zoom out a bit, we will see quadratic corrections, but higher corrections will still be mostly-negligible\".\n",
        "\n",
        "It somewhat came to a surprise to discover that an extremely simple nonlinearity, which furthermore happens to be scale invariant, usually performs really well in comparison - the \"rectified linear unit\",\n",
        "$x\\mapsto (x+|x|)/2$. There was a natural drive towards such a very simple function from the desire to avoid complicated numerical calculations such as doing an exponential - and it stuck when it showed good performance.\n",
        "\n",
        "More recently, there have been variations on the topic, such as ELU and SELU, but ReLU remains an important workhorse.\n",
        "\n",
        "It is interesting to ponder what the functions described by exclusively-ReLU deep networks look like: these are continuous functions that are affine-linear on (generalized) polyhedral cells. (\"Generalized\" since they may extend to infinity.) Naturally, \"gradients just propagate through, even to very deep layers\".\n",
        "\n",
        "The power of a deep ReLU network is nicely illustrated in the TensorFlow Playground by doing a \"swiss roll with noisy data\" problem using only the x/y coordinate as input features, and going for a maximum-capacity network, even without any regularization - but one really has to watch the training process to appreciate this:\n",
        "\n",
        "(See screenshot \"ReLU Activation\" on \"supplementary material\" document.)\n",
        "\n",
        "#### **Dropout Regularization**\n",
        "\n",
        "Looking at some TensorFlow Playground training runs for the \"swiss roll\" problem that use the same quite noisy input data, but started from differently initialized random weights, it is not surprising that we get roughly-comparable classifier performance, but both models made different doubtful decisions about where to make the contour look complicated to net a few more examples and get slightly lower loss on the training set.\n",
        "\n",
        "So, each model will have \"quirks\". Naturally, we would expect that if we just did what we discussed earlier, combining the assessments of different (perhaps not quite independent) \"experts\", such as majority-vote-of-5-differently-trained-models, we should be able to average out such \"structure hallucinations\". Of course, training and deploying multiple models is expensive, so: can we perhaps use some variant of this idea which retains some of the \"averaging over different models\" property while not being so expensive?\n",
        "\n",
        "One idea here is to use \"dropout\" layers: During the training process, we keep randomly disabling some units (but correspondingly scaling up the total input to a unit that has temporarily lost some of its input units) in changing patterns. Effectively, we are training an exponentially large family of networks (since with $N$ \"faulty\" units, we have $\\sim 2^N$ ways to disable half\n",
        "of them) which are all obtained from a \"master network\" by turning off some units.\n",
        "\n",
        "Another way to think about this is that \"dropout\" punishes complex co-adaptation of many units. If a complex hypothesis is realized by having some specific set of 10 units activate in a particular pattern, \"dropout\" makes it unlikely that they all are available at the same time, so, less complex hypotheses that only require two or three units to cooperate are favored over intricate explanations.\n",
        "\n",
        "(See screenshots \"Dropout\" on \"supplementary material\" document.)\n",
        "\n",
        "#### **Early Stopping**\n",
        "\n",
        "This is in the category of \"sometimes it helps, but sometimes we observe the opposite, and it helps more to keep training even when the model stopped learning anything\".\n",
        "\n",
        "The basic idea is that it can happen that a model first learns the overall structure of the problem, those aspects that generalize well, but as it keeps being fed the training examples, it will increasingly fine-tune on accidental properties of the training set - so, we should be able to limit overfitting by stopping the training process early, typically according to some heuristics.\n",
        "\n",
        "#### **Small Batch Sizes**\n",
        "\n",
        "This point is controversial - there are indications that, while there is some truth to this advice, the opposite also holds.\n",
        "\n",
        "Overall, neural network training amounts to finding some minimum (in weight/bias parameter space) of a \"loss: function that has many local minima (at the very least since we can always permute/relabel units and get an equivalent network). If we use smallish batch sizes (perhaps 32 or 64) to estimate gradients, that makes gradients inherently noisy, and this noisiness makes us not see narrow basins in the loss function, going for larger, \"more robust\" minima instead.\n",
        "\n",
        "#### **Convolutional Architectures**\n",
        "\n",
        "So far, we fed our classifiers one-dimension-per-pixel data vectors.\n",
        "\n",
        "Now, if we would in advance pick an image-scrambling permutation of pixels\n",
        "and applied this in the same way to all training and test examples, this would make the problem no more difficult for the ML architectures we have seen so far, but would make the problem *much* harder for a human. So, clearly, the problem has extra structure which we do not even remotely exploit yet.\n",
        "\n",
        "The MNIST dataset is normalized to always have the ink-center-of-gravity in the middle of the image, and also in some other ways. This makes this item somewhat a case of \"this happens to work also on MNIST, despite the major reasons why this is a good thing applying to a limited extent\". Sticking with MNIST, one way to think about the problem is that we might be able to reduce \"overfitting\" (so, mistaking accidental structure observed in the training set for relevant)\n",
        "by applying some data-reduction that we would expect to reduce such accidental features. Obviously, digits are a quite anthropomorphic solution to the problem of communicating data between humans - in the sense that doing the same between computers, we would likely go for a more barcode or QR-code like solution. So, unsurprisingly, digits work reasonably well even for people with slightly bad eyesight - they do not contain relevant fine detail that must be exactly right.\n",
        "\n",
        "So, one might wonder whether blurring the image a bit could help with classification. A \"blurring\" transform basically amounts to performing a convolution with some kernel, such as a Gaussian. This leaves the question: What kernel to use? If we were to answer \"this is ML, so we might simply treat the kernel's parameters as learnable and use gradient descent to find out what a good kernel might be\", and perhaps add \"let's blur in more than one way at the same time\", we basically have invented \"Convolutional Neural Networks\".\n",
        "\n",
        "Another way to think about this: If we humans look at an object, it mostly does not matter much whether it sits right in the center of our field of vision, or is a tiny bit displaced to the left, right, or up, or down. So, for many image classifiaction problems, there is some inherent translational symmetry in the task: If I want to know whether there is a frog in an image, then it should not matter for detecting the frog if the camera \"pointed two pixels further to the left\" when the picture was taken. So, we might want to do localized feature-extraction that is only sensitive to some small windowed region in the image, and slide that window over the entire image, both horizontally and vertically. Here, \"each window gets treated the same\", in the sense that we use the same weights independent of window-position. So, in training, if we have frogs in 4 out of 16 batch-examples, then such a set-up will try to tweak the convolution kernel(s) in such a way that they become sensitive to the differences between images-with-frogs and images-without-frogs, irrespective of how we have to place the window(s) to best fit the frogs.\n",
        "\n",
        "Right after a convolutional layer, which convolves window-wise with a collection of learnable kernels, one typically puts a resolution-reducing layer, often max-pooling. About max-pooling, Geoffrey Hinton has (in)famously said: \"The pooling operation used in convolutional neural networks is a big mistake and the fact that it works so well is a disaster.\" Here, we contend ourselves with observing that \"it often works quite well.\"\n"
      ],
      "metadata": {
        "id": "ANdXNBaEF4GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we proceed with `tf` code again, we might have to re-start the runtime\n",
        "# system and re-run the very first cell of this notebook, which re-imports\n",
        "# TF and other modules, and loads the dataset."
      ],
      "metadata": {
        "id": "opjSYLTg9DOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us put some of these ideas to the test.\n",
        "# Example adjusted from: https://keras.io/examples/vision/mnist_convnet/\n",
        "\n",
        "\n",
        "cnn_model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(50, activation='relu'),\n",
        "        tf.keras.layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "if True:\n",
        "  # This can take about half an hour or so. Feel free to disable.\n",
        "  cnn_model.fit(ds_train, epochs=30, validation_data=ds_validation)\n"
      ],
      "metadata": {
        "id": "Y__xJg17Ijbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "  # Some extra training, for refinement - feel free to disable.\n",
        "  cnn_model.fit(ds_train, epochs=2, validation_data=ds_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym7vWD04ENkU",
        "outputId": "12da0fc3-3142-4c84-8dc6-328427f50705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1407/1407 [==============================] - 58s 41ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0311 - val_sparse_categorical_accuracy: 0.9904\n",
            "Epoch 2/2\n",
            "1407/1407 [==============================] - 57s 41ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0306 - val_sparse_categorical_accuracy: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLQzadFS1F4s",
        "outputId": "c5620ca9-5721-473d-ddf4-8f9ee7333f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                80050     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,376\n",
            "Trainable params: 99,376\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we have here may well be superhuman ability at reading handwritten digits\n",
        "which we can readily deploy as a 400 KB model file on even quite cheap microcontrollers. This certainly is interesting.\n",
        "\n",
        "However, given that we still did not even try hard yet, this illustrates another point: \"MNIST is in general too simple to demonstrate superiority of some ML method\" and \"just about every idea works well on MNIST\".\n"
      ],
      "metadata": {
        "id": "49teLTrfu3mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us download/save HDF5 and tflite forms of this model.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!rm -rf mnist_cnn_model.h5\n",
        "\n",
        "if 'SAVE-TRAINED-MODEL' and False:  # Remove 'and False' to save the model.\n",
        "  cnn_model.save('mnist_cnn_model.h5')\n",
        "  !ls -la mnist_cnn_model.*\n",
        "  cnn_converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
        "  tflite_cnn_model = cnn_converter.convert()\n",
        "  #\n",
        "  # Save the model.\n",
        "  with open('mnist_cnn_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_cnn_model)\n",
        "  #\n",
        "  files.download('mnist_cnn_model.h5')\n",
        "  files.download('mnist_cnn_model.tflite')\n",
        "\n",
        "\n",
        "if 'UPLOAD-MODEL' and True:  # Upload a model instead.\n",
        "  model_data = next(iter(files.upload().values()))\n",
        "  with open('mnist_cnn_model.h5', 'wb') as h_model:\n",
        "    h_model.write(model_data)\n",
        "  reloaded_cnn_model = tf.keras.models.load_model(\"mnist_cnn_model.h5\")\n",
        "  #\n",
        "  print(\n",
        "      f'Test set accuracy: {reloaded_cnn_model.evaluate(ds_test)[1] * 100:.2f}%'\n",
        "      )\n"
      ],
      "metadata": {
        "id": "hhL3f8AroX9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e521ffb9-6172-4a9e-c74f-bf83f1028053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9917\n",
            "Test set accuracy: 99.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other major architectural ideas\n",
        "\n",
        "We discussed convolutional networks for image recognition tasks, and also some of the common approaches to improve model performance (which typically means: generalization).\n",
        "\n",
        "Our next major focus will be \"using the TensorFlow machinery to do Physics with it - perhaps without any ML involved\". So, this may be a good opportunity to discuss a few other important general ML-related ideas."
      ],
      "metadata": {
        "id": "IhkCFZELY-6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings\n",
        "\n",
        "Much of \"supervised Machine Learning\" (i.e. we have target labels) typically is about:\n",
        "  \n",
        "  1. Representing some aspect(s) of the real world we care about\n",
        "     as a high-dimensional vector. (This might be: an image,\n",
        "       a molecular structure, a sentence, a medical record, etc.)\n",
        "\n",
        "  1. Defining a \"model\" $m_{\\vec \\theta}$\n",
        "     with trainable parameters $\\vec\\theta\\in\\mathbb{R}^D$ that can\n",
        "     produce the desired output.\n",
        "\n",
        "  1. Obtaining training examples and tweaking model parameters\n",
        "     (typically via some variant of stochastic gradient descent)\n",
        "     to handle training set examples well.\n",
        "\n",
        "  1. Measuring performance on a validation-set.\n",
        "\n",
        "  1. Once everything looks good, measuring how well the model\n",
        "     generalizes on the test set, and deploying the model.\n",
        "\n",
        "We want to focus on 1.: How do we turn something like a sentence into a vector?\n",
        "\n",
        "\n",
        "The \"[Netflix Prize Problem](https://en.wikipedia.org/wiki/Netflix_Prize)\" provides an interesting setting to study this question. The Wikipedia article has details about the back story, but in a nutshell, this was about the Netflix video streaming company setting up a $1M competition back in 2006 for building a video recommendation system that outperforms their own system by at least 10%.\n",
        "\n",
        "Academically, what was interesting about this problem was that Netflix provided a very large training dataset. Getting training data labels is generally expensive, and here the research community had an opportunity to use a dataset much larger than what they normally had available, at the order of 100M training examples.\n",
        "\n",
        "The problem was as follows: Netflix customers watch movies, and get an opportunity to rate how well they enjoyed a movie right after they watched it.\n",
        "These ratings do obviously contain personal preferences about movies, and so it clearly is attractive for Netflix to have a recommendation system that produces individualized suggestions about what other movies a customer might enjoy watching.\n",
        "\n",
        "For our purposes, we can imagine the overall setting to be as follows: We have a large \"user movie ratings\" matrix $R_{um}$, where user $u$ rates movie $m$ - let's say with score $R_{um}\\in [-1.. 1] \\cup {\\rm NaN}$, where ${\\rm NaN}$ is supposed to mean: \"this user has not rated (perhaps not watched) that movie\".\n",
        "We might have additional information about movies, but here, we want to focus exclusively on this matrix.\n",
        "\n",
        "The matrix that we are given has some entries blanked out - Netflix knows how the given user rated the given movie, but for some (perhaps a million or so) ratings, they do not tell us and instead have put a ${\\rm NaN}$ entry there, just as if the user had not yet rated the movie. We do not know which entries are the missing ones, but we want to build a system that can predict these ratings well.\n",
        "\n",
        "\n",
        "**Let us have a break here and give everybody 10 minutes to think about the problem.**\n",
        "\n",
        "In the end, the prize was won in 2009, in a \"photo finish\". The winning team did a hundred different things, but we want to focus on the core idea.\n",
        "\n",
        "This was simply to try to find two matrices $U, M$ such that $R\\approx UM$ holds for the known entries. With indices, $R_{um}=\\tilde U_{uk}\\,\\tilde M_{km}$. Here, $u$ is still a user-index (going up to perhaps $100\\,000$), and $m$ is still a movie index (going up to maybe $10\\,000$ or so). The range of the index $k$ is small-ish, perhaps going up to $K=50$.\n",
        "\n",
        "We see how we can regard this as an optimization problem. We also immediately see how we can use such a factorization to make predictions. But why is doing this useful?\n",
        "\n",
        "Suppose individual customers have movie preferences that could be described as \"generally likes Jackie Chan movies\", \"likes comedy\", \"dislikes horror movies\". Now, if we had a fixed list of perhaps 200 such categories, we might try to get to a quantitative prediction if we find every user's and every movie's \"profile\" as a vector of quantitified alignment with each category.\n",
        "Then, the alignment between a given user's and movie's profile should allow us to predict an unknown rating.\n",
        "\n",
        "The beauty of this \"matrix factorization\" approach is that it determines these categories for us, in such a way that they are most useful for the problem at hand!\n",
        "\n",
        "Now, of course, as stated, the problem has a $GL(K)$ ambiguity, since we can always transform $\\tilde U\\to \\tilde U \\Lambda$, $\\tilde M\\to \\Lambda^{-1} \\tilde M$, with\n",
        "$\\Lambda\\in GL(K)$. But let's say we deal with this somehow, perhaps by additionally postulating that every row-vector of $\\tilde U$ and every column-vector of $\\tilde M$ must be length-1. This would then still leave us with some ambiguity (we could still do an $O(K)$ rotation of the coordinate basis), but apart from such details, we are left with a linear preference model where the problem itself seeks out the relevant directions.\n",
        "\n",
        "Another way to view this problem: If all entries of $R$ were known, it very likely would not be a \"random\" matrix but have extra structure. So, the question is: if we wanted to do data reduction and store far fewer elements, what would be a good proposal to still get a reasonably good approximation to the original matrix? Intuitively, \"the best thing we can usually do\" is to perform a Principal Component Analysis. This amounts to writing the matrix as a product $R=USV^T$ where here, since $R$ is real, $U$ and $V$ are orthogonal, and $S$ is rectangular with entries only on the diagonal~$S_{(j)(j)}$ - and then trimming $S$ by only retaining the $K$ largest-magnitude \"generalized eigenvalues\". So, the approach is: \"Perform a Singular Value Decomposition, and project out all smallish generalized eigenvalues\". This is, of course, a tried and tested pre-Deep-Learning ML approach that is widely used in many disciplines, also in financial analysis.\n",
        "\n",
        "Can we then interpret these \"principal axes\"? It turns out that, indeed, if we work this out for the Netflix matrix, we find that the two most relevant dimensions are \"Drama-vs-Comedy\" and \"Unsurprising-Plot-vs-Plot-Twists\".\n",
        "\n",
        "A nicely readable article about this is: [Matrix Factorization Techniques for Recommender Systems](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf).\n",
        "\n",
        "\n",
        "Now, what does this mean for Deep Learning? A basic insight is that if we have tokenized input (such as for text: each word or multi-word term in the dictionary is one token), we often can simply map each token to some $K$-dimensional vector with a trainable mapping (which we call an \"embedding\"), and leave it to the problem at hand to adjust the token-to-vector mapping in a way that maximizes usefulness-for-the-problem.\n",
        "\n",
        "This approach has produced some interesting surprises. Leaving out some (not quite irrelevant) detail, training a word embedding model on a problem that involves examples from news articles, for example, one may well find that the embedding evolved some lattice-like structure.\n",
        "If $E: {\\rm token}\\to{\\mathbb R}^K$ is the trained token-embedding function, we may find that equations such as $E({\\rm Paris}) - E({\\rm France}) + E({\\rm Germany}) \\approx E({\\rm Berlin})$ hold (in the sense that among the nearest neighbors of the left-hand-side vector, we find the embedding vector for \"Berlin\" on typically the 1st, but generally maybe at most 2nd or 3rd place).\n",
        "\n",
        "Google put some code from 2013 online that allows exploring this phenomenon.\n",
        "It meanwhile has been affected by some moderate \"bit rot\", but for those who are curious, the web page is\n",
        "[https://code.google.com/archive/p/word2vec/](https://code.google.com/archive/p/word2vec/), and the code archive is:\n",
        "[https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip](https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip)\n",
        "\n",
        "\n",
        "## The wider ML Landscape\n",
        "\n",
        "Some important notions and ideas from the wider Machine Learning landscape that we at least should have mentioned, but will not have any time to go into detail about.\n",
        "\n",
        "  * Unsupervised Learning\n",
        "\n",
        "    In general: Learning where we have no ground truth labels.\n",
        "    * Autoencoders (Variations on the \"input $\\to$ {compact representation} $\\to$ original\" idea.)\n",
        "    * t-SNE as a \"useful heuristic for visualizing in 2d or 3d how data\n",
        "      clusters in high dimensions\".\n",
        "\n",
        "  * Semi-Supervised Learning\n",
        "\n",
        "    Learning where we have some labeled examples, and many more\n",
        "    unlabeled examples. Idea: \"Knowing how stuff generally looks like\n",
        "    will typically help\".\n",
        "\n",
        "  * Reinforcement Learning\n",
        "\n",
        "    Learning behavior from reward observations.\n",
        "\n",
        "  * Regression Problems\n",
        "\n",
        "    Estimating a non-discrete quantity.\n",
        "    Key questions revolve around \"how much spread is there in the 'labels'\",\n",
        "    and 'what features allow me to explain how much of that spread?'\n",
        "    I.e. \"Standard deviation of the height of all children attending\n",
        "    primary school is $X$, but if I know their age, I can predict\n",
        "    their height with standard deviation $Y<X$.\n",
        "\n",
        "  * Non-Neural-Network Approaches\n",
        "\n",
        "    * K-Means Classifiers\n",
        "    * Support Vector Machines and Kernel Machines\n",
        "\n",
        "  * Specialized NN architectures\n",
        "\n",
        "    * Sequence-to-Sequence learning: LSTM ('ancient' but quite powerful).\n",
        "    * Graph-NNs(/-CNNs)\n",
        "    * \"Transformer Architectures\"\n",
        "      More recent, quite powerful, we are still in the process\n",
        "      of properly understanding what they can do and how they work.\n",
        "      Basis for large language models such as\n",
        "      [GPT-3](https://en.wikipedia.org/wiki/GPT-3).\n",
        "    * Generative Adversarial Networks - for generating e.g.\n",
        "      realistic-looking art.\n",
        "      \n",
        "      Also, for example: \"Neural Photo Editing\"\n",
        "      ([Example YouTube video](https://www.youtube.com/watch?v=FDELBFSeqQs) - [paper](https://arxiv.org/abs/1609.07093)).\n",
        "\n",
        "  * Tweaking pre-trained models;\n",
        "    [TensorFlow Hub](https://www.tensorflow.org/hub)"
      ],
      "metadata": {
        "id": "MADACcFDbvvo"
      }
    }
  ]
}